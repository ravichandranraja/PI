# Text to Vedio
import torch
import diffusers
from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler
from diffusers.utils import export_to_video
import streamlit as st
import numpy as np 

# Title and User Input
st.title("Text-to-Video with Streamlit")
prompt = st.text_input("Enter your text prompt:", "Spiderman is surfing")

# Button to trigger generation
if st.button("Generate Video"):  
    # Ensure you have 'accelerate' version 0.17.0 or higher 
    import accelerate # This line was incorrectly indented
    if accelerate.__version__ < "0.17.0":
        st.warning("Please upgrade 'accelerate' to version 0.17.0 or higher for CPU offloading.")
    else:
        with st.spinner("Generating video..."):
            # Define the pipeline for image generation
            pipe = DiffusionPipeline.from_pretrained("damo-vilab/text-to-video-ms-1.7b", 
                                                     torch_dtype=torch.float16,                                                 
                                                     variant="fp16",                                                 
                                                     device="cpu") 
            pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
            pipe.enable_model_cpu_offload()  

            # Generate video frames
            video_frames = pipe(prompt, num_inference_steps=25).frames  

            # Create dummy frames for testing (replace with actual manipulation later)
            dummy_frames = [np.ones((256, 256, 3), dtype=np.uint8) for _ in range(20)]  

            # Export to video
            video_path = export_to_video(dummy_frames)

            # Display the video in the Streamlit app  
            st.video(video_path)
